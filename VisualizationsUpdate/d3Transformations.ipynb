{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d992e116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'median_listing_price_comparison.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = 'median_listing_price.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "us_data = data[data['RegionName'] == 'United States']\n",
    "latest_date = data.columns[-1]\n",
    "top10_regions = data[data['RegionName'] != 'United States'].sort_values(by=latest_date, ascending=False).head(10)\n",
    "\n",
    "combined_data = pd.concat([us_data, top10_regions])\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for _, row in combined_data.iterrows():\n",
    "    region_name = row['RegionName']\n",
    "    \n",
    "    time_series = [{\"date\": date, \"median_price\": row[date]} for date in data.columns[5:]]\n",
    "    \n",
    "    region_entry = {\n",
    "        \"region\": region_name,\n",
    "        \"time_series\": time_series\n",
    "    }\n",
    "    \n",
    "    json_data.append(region_entry)\n",
    "\n",
    "output_path = 'median_listing_price_comparison.json'  \n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c653131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769244cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'median_listing_price_comparison.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path = 'median_listing_price.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "us_data = data[data['RegionName'] == 'United States']\n",
    "latest_date = data.columns[-1]\n",
    "top10_regions = data.sort_values(by=latest_date, ascending=False).head(10)\n",
    "\n",
    "combined_data = pd.concat([us_data, top10_regions])\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for _, row in combined_data.iterrows():\n",
    "    region_name = row['RegionName']\n",
    "    \n",
    "    time_series = [{\"date\": date, \"median_price\": row[date]} for date in data.columns[5:] if not pd.isna(row[date])]\n",
    "    \n",
    "    region_entry = {\n",
    "        \"region\": region_name,\n",
    "        \"time_series\": time_series\n",
    "    }\n",
    "    \n",
    "    json_data.append(region_entry)\n",
    "\n",
    "output_path = 'median_listing_price_comparison.json' \n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c35179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top_10_cities_listing_price.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'median_listing_price.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "top_10_cities = data[(data['SizeRank'] <= 10)].sort_values(by='SizeRank')\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for _, row in top_10_cities.iterrows():\n",
    "    region_name = row['RegionName']\n",
    "    \n",
    "    time_series = [{\"date\": date, \"median_price\": row[date]} for date in data.columns[5:] if pd.notna(row[date])]\n",
    "    \n",
    "    region_entry = {\n",
    "        \"region\": region_name,\n",
    "        \"time_series\": time_series\n",
    "    }\n",
    "    \n",
    "    json_data.append(region_entry)\n",
    "\n",
    "output_path = 'top_10_cities_listing_price.json'  # Update with your desired output path\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ae2065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\alexis\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d6918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'UTF-16', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "file_path = 'redfin_housing_data.csv'\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c919d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to median_sale_price.json\n"
     ]
    }
   ],
   "source": [
    "file_path = 'redfin_housing_data.csv'  \n",
    "data = pd.read_csv(file_path, encoding='utf-16', sep='\\t')\n",
    "data['Median Sale Price'] = data['Median Sale Price'].replace({'\\$': '', 'K': '000'}, regex=True).astype(float)\n",
    "data['Month of Period End'] = pd.to_datetime(data['Month of Period End'], format='%B %Y')\n",
    "json_data = []\n",
    "for region in data['Region'].unique():\n",
    "    region_data = data[data['Region'] == region]\n",
    "    json_entry = {\n",
    "        \"region\": region,\n",
    "        \"time_series\": [\n",
    "            {\"date\": date.strftime('%Y-%m-%d'), \"median_price\": price}\n",
    "            for date, price in zip(region_data['Month of Period End'], region_data['Median Sale Price'])\n",
    "        ]\n",
    "    }\n",
    "    json_data.append(json_entry)\n",
    "\n",
    "output_path = 'median_sale_price.json' \n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24faef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to housing_metrics.json\n"
     ]
    }
   ],
   "source": [
    "file_path = 'redfin_housing_data.csv'  \n",
    "data = pd.read_csv(file_path, encoding='utf-16', sep='\\t')\n",
    "\n",
    "columns_to_clean = ['Median Sale Price', 'Homes Sold', 'New Listings', 'Days on Market']\n",
    "for col in columns_to_clean:\n",
    "    data[col] = data[col].replace({r'[,\\$K]': ''}, regex=True).astype(float)\n",
    "\n",
    "data['Month of Period End'] = pd.to_datetime(data['Month of Period End'], format='%B %Y')\n",
    "\n",
    "json_data = []\n",
    "for region in data['Region'].unique():\n",
    "    region_data = data[data['Region'] == region]\n",
    "    json_entry = {\n",
    "        \"region\": region,\n",
    "        \"time_series\": [\n",
    "            {\n",
    "                \"date\": date.strftime('%Y-%m-%d'),\n",
    "                \"median_price\": price,\n",
    "                \"homes_sold\": homes_sold,\n",
    "                \"new_listings\": new_listings,\n",
    "                \"days_on_market\": days_on_market\n",
    "            }\n",
    "            for date, price, homes_sold, new_listings, days_on_market in zip(\n",
    "                region_data['Month of Period End'],\n",
    "                region_data['Median Sale Price'],\n",
    "                region_data['Homes Sold'],\n",
    "                region_data['New Listings'],\n",
    "                region_data['Days on Market']\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    json_data.append(json_entry)\n",
    "\n",
    "\n",
    "output_path = 'housing_metrics.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0630e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Region\\tMonth of Period End\\tMedian Sale Price\\tMedian Sale Price MoM \\tMedian Sale Price YoY \\tHomes Sold\\tHomes Sold MoM \\tHomes Sold YoY \\tNew Listings\\tNew Listings MoM \\tNew Listings YoY \\tInventory\\tInventory MoM \\t Inventory YoY \\tDays on Market\\tDays on Market MoM\\tDays on Market YoY\\tAverage Sale To List\\tAverage Sale To List MoM \\tAverage Sale To List YoY '], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
